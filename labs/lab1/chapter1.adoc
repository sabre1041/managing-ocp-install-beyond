== Lab 1 - Lab Setup

Welcome! We are going to jump right into the lab implementation and then review the overall architecture and strategy afterward. You have been tasked with managing a Red Hat Container Platform environment running on the Red Hat OpenStack platform. Ansible Tower is also available and being used to execute and manage the overall installation of OpenShift.

NOTE: The installation of OpenShift Container Platform can take 20-25 minutes so must be started immediately. If bullet point 1 below takes longer than 1 minute to complete, skip it and go directly to bullet point 2.

## Configure Ansible Tower:
* From a local web browser open https://tower-<student_id>.rhte.sysdeseng.com[https://tower-<student_id>.rhte.sysdeseng.com]. This will be the tower instance that you checked out from the spreadsheet.
* Login with the following credentials:
 ** Username: **admin**
 ** Password: **rhte2017**

##  Create Tower Inventory

TIP: In this lab, whatever you put for “<YOUR STUDENT ID>” needs to be consistent throughout the rest of the lab. Failure to do so, can cause issues.

* Click "INVENTORIES" on the top navigation pane.
* Click "+ADD".
** Provide a name of: OpenShift
** In the “VARIABLES” pane, add the following content:

+

"- student_id: <YOUR STUDENT ID>"

+

** Click “SAVE”

* Click "ADD GROUP"
** Provide a name of "AWS"
** Choose a "SOURCE" of "Amazon EC2"
** Search for the "CLOUD CREDENTIAL" and select "AWS" and click "SELECT"
** Provide a "REGIONS" of "Asia Pacific (Singapore)"
** Provide the following "INSTANCE FILTER"

+

"tag:student_id=<YOUR STUDENT ID>"

+

** Select "Update on Launch"
** Click "SAVE"
*** Add the following variables to the "SOURCE VARIABLES" pane and then click "SAVE"


[source, bash]
----
regions: ap-southeast-1
hostname_variable: tag_Name
vpc_destination_variable: public_dns_name
----

* Click “ADD GROUP”
** Provide a name of “OSEv3”
** Choose a “SOURCE” of “Manual”
** Copy the following variables to the inventory script.  “REPLACE <student_id> with your student ID! student_id takes for form similar to student-1.  Use the same one you used before. There are **3** instances of <student_id> in the variables below - change them all.

+
[source, bash]
----
---
deployment_type: openshift-enterprise
osm_use_cockpit: no
openshift_master_default_subdomain: apps-<student_id>.rhte.sysdeseng.com
openshift_master_identity_providers:
- name: htpasswd_auth
  login: True
  challenge: True
  kind: HTPasswdPasswordIdentityProvider
  filename: /etc/origin/master/htpasswd
openshift_master_htpasswd_users:
  student: $apr1$5/tyREyX$faNZX.wbId4LGDkNYxJQZ0
openshift_master_image_policy_config:
  maxImagesBulkImportedPerRepository: 100
openshift_hosted_metrics_deploy: yes
openshift_hosted_metrics_storage_kind: dynamic
os_sdn_network_plugin_name: redhat/openshift-ovs-multitenant
osn_storage_plugin_deps: []
openshift_schedulable: True
openshift_hosted_router_selector: 'type=infra'
openshift_hosted_registry_selector: 'type=infra'
openshift_metrics_selector: "type=infra"
openshift_cloudprovider_kind: aws
openshift_master_cluster_hostname: "master-internal-<student_id>.rhte.sysdeseng.com"
openshift_master_cluster_public_hostname: "master-<student_id>.rhte.sysdeseng.com"
openshift_metrics_cassandra_storage_type: dynamic
openshift_disable_check: memory_availability
openshift_enable_service_catalog: true

openshift_cloudprovider_aws_access_key: "{{ lookup('env','AWS_ACCESS_KEY') }}"
openshift_cloudprovider_aws_secret_key: "{{ lookup('env','AWS_SECRET_KEY') }}"
openshift_node_labels: "{{ ec2_tag_node_labels }}"

# Default Node Selector Cannot be Used Due to Issue With Service Catalog Deployment. Is set during Postinstall playbook
#osm_default_node_selector: 'type=app'
----

** Click “SAVE”

In this section, we are going to configure groups.  This is important because this is the way that Ansible Tower constructs an inventory to pass to the openshift-ansible byo playbook.

** Click on “OSEv3”
*** Click on "ADD GROUP"
*** Create a group called “nodes”
*** Click “SAVE”

** Click on “nodes” under Groups
*** Click on "ADD GROUP"
*** Create a child group called “masters”
*** Click “SAVE”

**** At the same level as the "nodes"group, click "ADD GROUP".
**** Add another child group called “tag_lab_role_node” by clicking ADD GROUP.
**** Click SAVE
***** Click on the “masters” group
***** Create a child group called “tag_lab_role_master”
***** Click SAVE.

At this point, this is what your inventory group paths should look like:

[source, bash]
----
INVENTORIES -> OpenShift -> OSEv3 -> nodes -> tag_lab_role_node
INVENTORIES -> OpenShift -> OSEv3 -> nodes -> masters -> tag_lab_role_master
----

## Create Projects for Provision and Post-install Playbooks


* Click "PROJECTS" in the top navigation pane.
** Click "ADD".
** Provide a “NAME” of “Managing OCP from Install and Beyond”
** Choose "SCM TYPE" of "Git".
** Provide "SCM URL" of "https://github.com/sabre1041/managing-ocp-install-beyond.git" with a "SCM BRANCH" of "rhte".
** Select "Clean" and “Update on Launch” in the "SCM UPDATE OPTIONS"
** Click "SAVE"

* SSH to Tower - ssh -i rhte.pem ec2-user@<public_hostname_of_tower_VM>
+
[source, bash]
----
sudo -i

subscription-manager repos --enable="rhel-7-server-ose-3.6-rpms" && yum -y install openshift-ansible-playbooks && ln -s /usr/share /var/lib/awx/projects
----
+
** Click “ADD”
** Name: openshift-ansible
** SCM TYPE: Manual
** Playbook Directory: share
** Click “SAVE”


Now you should have two projects: "openshift-ansible" and "Managing OCP from Install and Beyond".

## Create Job Template for Deployment Provision

* Click "TEMPLATES" on the top navigation pane.
** Click "+ADD", select "Job Template"
** Provide a name of: Deployment-1-Provision
** Click the "SEARCH" icon for the "INVENTORY" input box and select "OpenShift Inventory" and then click "SELECT".
** Click the "SEARCH" icon for the "PROJECT" input box and select "Managing OCP from Install and Beyond" and then click "SELECT".
** Click the "Choose a playbook" in the "PLAYBOOK" input box and select the "openshift-infra/aws_create_hosts.yml" playbook.
** Click the "SEARCH" icon for the "MACHINE CREDENTIAL" input box and select "RHTE SSH Machine" and then click "SELECT".
** Click the "SEARCH" icon for the "SELECT CLOUD CREDENTIAL" input box and select "AWS" and then click "SELECT".
** Add the following to the "EXTRA VARIABLES" pane.

+
[source, bash]
----
ec2_access_key: "{{ lookup('env', 'AWS_ACCESS_KEY') }}"
ec2_secret_key: "{{ lookup('env', 'AWS_SECRET_KEY') }}"
student_id: <YOUR STUDENT ID>
openshift_cluster_public_url: "https{{':'}}//master-{{ student_id }}.{{ domain_name }}{{':'}}8443"
----

** Click "SAVE".

## Create Job Template for Deployment Install

* Click "+ADD", select "Job Template"
** Provide a name of: Deployment-2-Install
** Click the "SEARCH" icon for the "INVENTORY" input box and select "OpenShift Inventory" and then click "SELECT".
** Click the "SEARCH" icon for the "PROJECT" input box and select "openshift-ansible" and then click "SELECT".
** Click the "Choose a playbook" in the "PLAYBOOK" input box and select the "ansible/openshift-ansible/playbooks/byo/config.yml" playbook.
** Click the "SEARCH" icon for the "MACHINE CREDENTIAL" input box and select "RHTE SSH" and then click "SELECT".
** Click the "SEARCH" icon for the "SELECT CLOUD CREDENTIAL" input box and select "AWS Credential" and then click "SELECT".
** Under Options, check “Enable Privilege Escalation”
** Click “SAVE”

## Create Job Template for Deployment Post-Install

* Click "+ADD", select "Job Template"
** Provide a name of: Deployment-3-Post-Install
** Click the "SEARCH" icon for the "INVENTORY" input box and select "OpenShift Inventory" and then click "SELECT".
** Click the "SEARCH" icon for the "PROJECT" input box and select "Managing OCP from Install and Beyond" and then click "SELECT".
** Click the "Choose a playbook" in the "PLAYBOOK" input box and select the "openshift-infra/openshift_postinstall.yml" playbook.
** Click the "SEARCH" icon for the "MACHINE CREDENTIAL" input box and select "RHTE SSH" and then click "SELECT".
** Click the "SEARCH" icon for the "SELECT CLOUD CREDENTIAL" input box and select "AWS Credential" and then click "SELECT".
** Click “SAVE”

You should have 3 job templates: "1-Deploy OpenShift on AWS", "Deployment-2-Install", and "Deployment-3-Post-Install"

=======
## Add Scaleup Job Templates

Refer to the previous lab on creating Job Templates for details. Here are the overall requirements:

### Create Job Template for Scaleup Provision

** Create Job Template
** Name: “Scaleup Provision”
** Playbook: “openshift-infra/aws_add_node.yml”
** Add following variables:

[source, bash]
----
ec2_access_key: "{{ lookup('env', 'AWS_ACCESS_KEY') }}"
ec2_secret_key: "{{ lookup('env', 'AWS_SECRET_KEY') }}"
student_id: <STUDENT ID HERE>
----

** Same inventory, project, machine cred, cloud cred as “Deployment Provision”
** Click “SAVE”

### Create Job Templte for Scaleup Install

** Create Job Template
** Name: “Scaleup Install”
** Playbook: “ansible/openshift-ansible/playbooks/byo/openshift-node/scaleup.yml”
** Same inventory, project, machine cred, cloud cred as “Deployment Install”
** Enable Priveliged Escalation
** Click “SAVE”

### Create Job Templte for Scaleup Post Install

** Create Job Template
** Name: “Scaleup Post Install”
** Playbook: “openshift-infra/openshift_postinstall.yml”
** Same inventory, project, machine cred, cloud cred as “Deployment Install”
** Click “SAVE”

## Create Workflow Job Template for the Deployment

** Click "+ADD", select "Workflow Job Template"
** Provide a name of "1-Deploy OpenShift on AWS"
** Click “SAVE”
** Click “Workflow Editor”
** Click “Start” and a box will appear to the right.
** On the right under “Add Template” select “Deployment Provision” and “Select”
** Now click on the box after start labeled “Deploy Provision” and click the green “+” in the top right.
** Again, on the right under “Add a Template” select “Deployment Install” and “Select”
** Lastly, click on the new box again, green “+” in the top right.
** Select “Deployment Post-install” and “Select
** Select “SAVE” at the bottom right.
** Launch Workflow Job
** Click “Templates”
** Click rocket ship icon next to “1-Deploy OpenShift on AWS”
** Watch progress.

## Create Workflow Job Template for Scale Up

** Add Scaleup Workflow Job Template
** Refer to the previous lab on creating the Workflow for Deployment. Here are the overall requirements:
** Create Workflow Job Template
** Connect Job Templates as follows: “Scaleup Provision” -> “Scaleup Install” -> “Scaleup Post-install”
** Launch Scaleup Workflow Job
** Click “Templates”
** Click rocket ship icon next to “Scaleup”
** Watch progress.

## Ansible Tower CLI

[source, bash]
----
# yum -y install python2-pip git pyOpenSSL python-netaddr python-six python2-boto3 python-click python-httplib2

# pip install ansible-tower-cli
# pip install boto

# tower-cli config host <hostname>
# tower-cli config username admin
# tower-cli config password <password>
----

 .. After Student kicks off scale up playbook -
 .. SSH to tower instance, run some commands

** SSH to Tower - ssh -i rhte.pem ec2-user@<public_hostname_of_tower_VM>

[source, bash]
----
 .. sudo tower-manage --help
 .. Evaluate tower-cli on the Ansible Tower host
 .. sudo tower-cli version
 .. sudo tower-cli host list
 .. sudo tower-cli inventory list
 .. sudo tower-cli job list
 .. sudo tower-cli credential list
 .. sudo tower-cli job_template list
----

 image::images/image28.png[]
